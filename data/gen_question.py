import os
import json
import random
from pathlib import Path
import openai
from datetime import datetime
import time
import re
from dotenv import load_dotenv
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed

class QAGenerator:
    def __init__(self, output_dir="data/output", output_file="data/qa_dataset.jsonl", max_workers=4):
        self.output_dir = Path(output_dir)
        self.output_file = Path(output_file)
        self.client = None
        self.file_lock = threading.Lock()
        self.total_qa_count = 0
        self.train_count = 0
        self.eval_count = 0
        self.max_workers = max_workers  # å¹¶å‘å¤„ç†çš„æœ€å¤§çº¿ç¨‹æ•°
        self.processed_count = 0
        self.progress_lock = threading.Lock()
        self.setup_openai()
        
    def setup_openai(self):
        load_dotenv()
        
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            print("è¯·åœ¨.envæ–‡ä»¶ä¸­è®¾ç½®OPENAI_API_KEYï¼Œæˆ–è®¾ç½®ç¯å¢ƒå˜é‡")
            return

        base_url = os.getenv("OPENAI_BASE_URL")
        
        try:
            client_params = {"api_key": api_key}
            if base_url:
                client_params["base_url"] = base_url
                
            self.client = openai.OpenAI(**client_params)
            print("âœ“ OpenAIå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
            
        except Exception as e:
            print(f"âœ— OpenAIå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
            self.client = None
    
    def generate_qa_pairs(self, content, title):
        if not self.client:
            print("OpenAIå®¢æˆ·ç«¯æœªåˆå§‹åŒ–ï¼Œè·³è¿‡LLMè°ƒç”¨")
            return []
        
        system_prompt = """ä½ æ˜¯ä¸€ä½å¯¹å…šå¿ è¯šã€å­¦æœ¯æ¸Šåšçš„é©¬å…‹æ€ä¸»ä¹‰æ•™æˆã€‚è¯·åŸºäºä»¥ä¸‹æ–‡ç« å†…å®¹ç”Ÿæˆ5-20ä¸ªé«˜è´¨é‡çš„é—®é¢˜ã€‚è¦æ±‚ï¼š

0. ä¸¥æ ¼éµå®ˆä¸­åäººæ°‘å…±å’Œå›½çš„æ³•å¾‹æ³•è§„ï¼Œç¬¦åˆç¤¾ä¼šä¸»ä¹‰æ ¸å¿ƒä»·å€¼è§‚
1. åœ¨ä½ ç”Ÿæˆçš„æ¯ä¸ªé—®é¢˜ä¸­ï¼Œå¿…é¡»æ˜ç¡®æŒ‡å‡ºå…·ä½“çš„æ–‡ç« ç¯‡ç›®ï¼Œæ¯”å¦‚"æ¯›æ³½ä¸œåœ¨ã€Šåå¯¹æœ¬æœ¬ä¸»ä¹‰ã€‹ä¸­æå‡ºäº†å“ªäº›å…·ä½“çš„è°ƒæŸ¥æŠ€æœ¯ï¼Ÿ"ï¼Œè€Œä¸å¯ä»¥åªè¯´"æ¯›æ³½ä¸œæå‡ºäº†å“ªäº›å…·ä½“çš„è°ƒæŸ¥æŠ€æœ¯ï¼Ÿ"
2. é—®é¢˜è¦æœ‰æ·±åº¦ï¼Œèƒ½å¤Ÿæµ‹è¯•å¯¹æ–‡ç« å†…å®¹çš„ç†è§£
3. é—®é¢˜ç±»å‹è¦å¤šæ ·åŒ–ï¼šäº‹å®æ€§é—®é¢˜ã€ç†è§£æ€§é—®é¢˜ã€åˆ†ææ€§é—®é¢˜ç­‰
4. é¿å…è¿‡äºç®€å•çš„æ˜¯éé¢˜
5. ç¡®ä¿é—®é¢˜èƒ½å¤Ÿå¸®åŠ©å­¦ä¹ å’Œç†è§£æ–‡ç« çš„æ ¸å¿ƒè§‚ç‚¹

è¯·ä»¥ä»¥ä¸‹JSONæ ¼å¼è¿”å›ï¼ˆåªè¿”å›JSONï¼Œä¸è¦å…¶ä»–å†…å®¹ï¼‰ï¼š
[
    {"question": "é—®é¢˜å†…å®¹"},
    {"question": "é—®é¢˜å†…å®¹"}
]"""

        user_prompt = f"""æ–‡ç« æ ‡é¢˜ï¼š{title}

æ–‡ç« å†…å®¹ï¼š
{content}"""
        
        try:
            response = self.client.chat.completions.create(
                model="deepseek-chat",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=1,
                max_tokens=8192
            )
            
            response_text = response.choices[0].message.content.strip()
            
            try:
                qa_pairs = json.loads(response_text)
                return qa_pairs
            except json.JSONDecodeError:
                json_match = re.search(r'\[.*\]', response_text, re.DOTALL)
                if json_match:
                    qa_pairs = json.loads(json_match.group())
                    return qa_pairs
                else:
                    print(f"æ— æ³•è§£æLLMè¿”å›çš„å†…å®¹: {response_text[:200]}...")
                    return []
            
        except Exception as e:
            print(f"è°ƒç”¨LLMæ—¶å‡ºé”™: {e}")
            return []
    
    def determine_dataset_split(self):
        return "trainset" if random.random() < 0.9 else "evalset"
    
    def write_questions_to_file(self, questions_data):
        with self.file_lock:
            with open(self.output_file, 'a', encoding='utf-8') as f:
                for item in questions_data:
                    f.write(json.dumps(item, ensure_ascii=False) + '\n')
            
            self.total_qa_count += len(questions_data)
            train_new = sum(1 for item in questions_data if item['dataset_split'] == 'trainset')
            eval_new = len(questions_data) - train_new
            self.train_count += train_new
            self.eval_count += eval_new
            
            print(f"âœ“ å·²å†™å…¥ {len(questions_data)} ä¸ªé—®é¢˜åˆ°æ–‡ä»¶")
            print(f"  å½“å‰æ€»è®¡: {self.total_qa_count} ä¸ªé—®é¢˜ (è®­ç»ƒé›†: {self.train_count}, éªŒè¯é›†: {self.eval_count})")
    
    def update_progress(self, total_articles):
        """æ›´æ–°å¹¶æ˜¾ç¤ºè¿›åº¦"""
        with self.progress_lock:
            self.processed_count += 1
            progress = self.processed_count / total_articles * 100
            print(f"ğŸ“Š è¿›åº¦: {self.processed_count}/{total_articles} ({progress:.1f}%)")
    
    def process_single_article(self, article_dir, total_articles=None):
        content_file = article_dir / "content.txt"
        
        if not content_file.exists():
            print(f"è·³è¿‡ {article_dir.name}ï¼šæ²¡æœ‰æ‰¾åˆ°content.txt")
            if total_articles:
                self.update_progress(total_articles)
            return
        
        try:
            with open(content_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            title = article_dir.name
            print(f"ğŸ“– å¤„ç†æ–‡ç« : {title}")
            
            questions = self.generate_qa_pairs(content, title)
            
            if not questions:
                print(f"âŒ æœªèƒ½ä¸ºæ–‡ç«  {title} ç”Ÿæˆé—®é¢˜")
                if total_articles:
                    self.update_progress(total_articles)
                return
            
            results = []
            for q in questions:
                if 'question' in q:
                    item = {
                        'q': q['question'],
                        'source_article': title,
                        'dataset_split': self.determine_dataset_split(),
                        'generated_time': datetime.now().isoformat()
                    }
                    results.append(item)
            
            if results:
                self.write_questions_to_file(results)
                print(f"âœ… æˆåŠŸå¤„ç†æ–‡ç«  {title}ï¼Œç”Ÿæˆ {len(results)} ä¸ªé—®é¢˜")
            else:
                print(f"âŒ æ–‡ç«  {title} æ²¡æœ‰ç”Ÿæˆæœ‰æ•ˆçš„é—®é¢˜")
            
            if total_articles:
                self.update_progress(total_articles)
            
        except Exception as e:
            print(f"âŒ å¤„ç†æ–‡ç«  {article_dir.name} æ—¶å‡ºé”™: {e}")
            if total_articles:
                self.update_progress(total_articles)
    
    def run(self):
        if not self.output_dir.exists():
            print(f"è¾“å‡ºç›®å½• {self.output_dir} ä¸å­˜åœ¨")
            return
        
        self.output_file.parent.mkdir(parents=True, exist_ok=True)
        
        with open(self.output_file, 'w', encoding='utf-8') as f:
            pass
        
        article_dirs = [d for d in self.output_dir.iterdir() if d.is_dir()]
        article_dirs.sort()
        
        print(f"ğŸš€ å¼€å§‹å¹¶è¡Œå¤„ç†ï¼Œæ‰¾åˆ° {len(article_dirs)} ä¸ªæ–‡ç« ç›®å½•")
        print(f"ğŸ”§ ä½¿ç”¨ {self.max_workers} ä¸ªå¹¶å‘çº¿ç¨‹")
        print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {self.output_file}")
        
        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œå¤„ç†
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_article = {
                executor.submit(self.process_single_article, article_dir, len(article_dirs)): article_dir 
                for article_dir in article_dirs
            }
            
            # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
            for future in as_completed(future_to_article):
                article_dir = future_to_article[future]
                try:
                    future.result()  # è·å–ç»“æœï¼Œå¦‚æœæœ‰å¼‚å¸¸ä¼šæŠ›å‡º
                except Exception as exc:
                    print(f"âŒ æ–‡ç«  {article_dir.name} å¤„ç†æ—¶å‘ç”Ÿå¼‚å¸¸: {exc}")
        
        print(f"\nğŸ‰ å¹¶è¡Œå¤„ç†å®Œæˆï¼")
        print(f"ğŸ“Š æ€»å…±ç”Ÿæˆ {self.total_qa_count} ä¸ªé—®é¢˜")
        print(f"ğŸ“š è®­ç»ƒé›†: {self.train_count} ä¸ªé—®é¢˜")
        print(f"ğŸ§ª éªŒè¯é›†: {self.eval_count} ä¸ªé—®é¢˜")
        print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {self.output_file}")

def main():    
    print("ğŸ¯ å¼€å§‹ç”Ÿæˆé—®é¢˜æ•°æ®é›†...")
    generator = QAGenerator(max_workers=8)
    generator.run()
    print("âœ¨ å®Œæˆï¼")

if __name__ == "__main__":
    main()
